# ToadUI - Demos

This folder contains examples built using ToadUI. They can be run using:
```base
python demos/name_of_demo.py
# or, if using uv
uv run demos/name_of_demo.py
```

Many of the scripts have additional flags that can be viewed by adding `--help` when running the scripts. Several scripts support webcams as inputs, you can type: `cam` when prompted for a video input to use a webcam as the video source.

These demos are written so that the main functionality fits within ~100 lines of code. They're meant to be simple to follow and/or modify.  The main logic is usually found at the end of the script, under a `with window.auto_close` block, so start there if you'd like to make changes.

## colorspace_viewer.py

This demo displays [color space](https://en.wikipedia.org/wiki/Color_space) information for images, videos or webcam inputs.

<p align="center">
  <img src="https://github.com/user-attachments/assets/3e7a1f02-7830-4921-8d43-7602e42a4e58" style="width:400px">
</p>

In addition to showing separate channel information for a variety of different color spaces (e.g. [RGB](https://en.wikipedia.org/wiki/RGB_color_spaces), [LAB](https://en.wikipedia.org/wiki/CIELAB_color_space), [HSV](https://en.wikipedia.org/wiki/HSL_and_HSV), [YCrCb](https://en.wikipedia.org/wiki/YCbCr), [XYZ](https://en.wikipedia.org/wiki/CIE_1931_color_space) etc.), there are controls to [threshold](https://en.wikipedia.org/wiki/Thresholding_(image_processing)) each of the separate color channels as well as apply [histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization). It's also possible to visualize the histograms themselves as simple line or bar plots.

**UI Elements:**  ToggleButton, RadioBar, MultiSlider, SimpleHistogramPlot, GridStack, Swapper

## game_of_life.py

This demo runs an implementation of [Conway's Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life), while maintaining a heatmap.

<p align="center">
  <img src="https://github.com/user-attachments/assets/cf151bb9-7806-43af-8027-a8dc07985d36" style="width:400px">
</p>

When active, the heatmap is visualized through colormapping, where cells are colored based on the length of time passed since the cell has been active. This helps to visualize the 'trail' of the patterns/structures generated by the simulation. It's also possible to directly click to modify cell states, as well as initializing using random patterns. Through script arguments, custom colormaps and/or a cell patterns can be provided.

**UI Elements:** ColormapsBar, TextCarousel, ImmediateButton, ToggleButton, Slider

## image_cropping.py

This demo runs a simple UI for cropping images or frames from videos.

<p align="center">
  <img src="https://github.com/user-attachments/assets/9b4e8329-f868-4597-9746-d38f43fdc3bb">
</p>

The UI includes support for interactive click-and-drag boxes. The built-in [selectROI](https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#ga99cbbe0e7ed2e099e52c367ea4306be4) from OpenCV provides similar functionality, but locks up the display while doing so. The ToadUI implementation allows for continuous rendering/UI updates as well as interactively modifiying the box after-the-fact.

**UI Elements:** FixedARImage, ZoomImage, Swapper, ToggleImageButton, EditBoxOverlay, DrawRectangleOverlay, VideoPlaybackSlider, PrefixedTextBlock


## ocv_edge_detection.py

This demo provides interactive control over multiple [edge detection algorithms](https://opencv.org/blog/edge-detection-using-opencv/) built into OpenCV, including [Sobel](https://en.wikipedia.org/wiki/Sobel_operator), [Laplacian](https://en.wikipedia.org/wiki/Discrete_Laplace_operator) and [Canny](https://en.wikipedia.org/wiki/Canny_edge_detector) edge detection, among others.

<p align="center">
  <img src="https://github.com/user-attachments/assets/3b75eedd-0b6e-4476-8f88-888bdd869f9a" style="width:400px">
</p>

This demo works on images, video or webcam inputs.

**UI Elements:** FixedARImage, Swapper, RadioBar, ToggleButton, MultiSlider, TextCarousel, PrefixedTextBlock


## ocv_grabcut.py

This demo provides a fully interactive version of the OpenCV implementation of the [GrabCut algorithm](https://docs.opencv.org/4.x/dd/dfc/tutorial_js_grabcut.html).

<p align="center">
  <img src="https://github.com/user-attachments/assets/f10949d2-6627-494b-bcd0-91db914f9b0a">
</p>

The UI includes support for segmenting parts of an image using bounding boxes as well as 'paint strokes' to indicate foreground/background regions. Both the box selection and painting are built directly into this demo, and so do not require the use of third party painting tools to generate masks, as is done in the [OpenCV documentation](https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html). Note that while this demo provides a sense of how the grabcut algorithm behaves, this is not an especially good technique for object segmentation nowadays. For example, in many use cases [tools](https://github.com/heyoeyo/muggled_sam?tab=readme-ov-file#run-image) using something like [Segment-Anything](https://github.com/facebookresearch/sam2) will be both faster and more accurate.

**UI Elements:** FixedARImage, Slider, OverlayStack, EditBoxOverlay, MousePaintOverlay

## ocv_lowpass_filtering.py

This demo provides interactive control over various [low-pass filtering](https://en.wikipedia.org/wiki/Low-pass_filter) (e.g. blurring) functions [built into OpenCV](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html) and includes non-linear options like [morphological](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html) and [Kuwahara](https://en.wikipedia.org/wiki/Kuwahara_filter) filtering.

<p align="center">
  <img src="https://github.com/user-attachments/assets/fb147a64-5055-4e43-8033-364d59d4cabf" style="width:400px">
</p>

This demo works on images, video or webcam inputs.

**UI Elements:** FixedARImage, Swapper, RadioBar, ToggleButton, Slider, TextCarousel, PrefixedTextBlock

## ocv_optical_flow.py

This demo provides an interactive visualization of the dense [optical flow](https://docs.opencv.org/4.x/d4/dee/tutorial_optical_flow.html) implementation built into OpenCV (i.e. the [calcOpticalFlowFarneback(...)](https://docs.opencv.org/4.10.0/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af) function). The input video is shown side-by-side with a false-color optical flow result (colors indicate direction of movement, for example, green is downward), along with the delta-x & delta-y flow components.

<p align="center">
  <img src="https://github.com/user-attachments/assets/c31bf4dc-e8a0-4c38-9d48-c7ed2f865895" style="width:400px">
</p>

The UI provides a one-to-one mapping of the OpenCV function arguments (obscure things like: `pyr_scale`, `levels`, `winsize` etc.), allowing the user to modify these in real-time while observing the optical flow results. This demo is a particularly good use case of ToadUI, providing a way to visualize a complex image processing routine, while also being interactive.

**UI Elements:** ToggleButton, Slider, PrefixedTextBlock, HoverLabelOverlay

## video_playback.py

This demo runs a simple video player UI. It's a good starter template for UIs involving video (or webcam) inputs.

<p align="center">
  <img src="https://github.com/user-attachments/assets/b5adf23e-a99a-4c54-a2c2-45fee0138963">
</p>

Unlike the [simple example](https://github.com/heyoeyo/toadui?tab=readme-ov-file#simple-example) found on the main README, this demo draws a circle that follows the mouse when hovering the video image. It also includes basic read-outs for the mouse positioning and support for stepping the video forwards/backwards using the arrow keys.

**UI Elements:** VideoPlaybackSlider, PrefixedTextBlock


## video_warping.py

This demo allows the user to warp image or video data, interactively.

<p align="center">
  <img src="https://github.com/user-attachments/assets/febf93c7-bd2a-4a77-8532-86208d95afb4" style="width:400px">
</p>

This demo supports the use of input images or videos, including webcams! Warping is done using [complex numbers](https://en.wikipedia.org/wiki/Complex_number) and the [OpenCV remap function](https://docs.opencv.org/3.4/d1/da0/tutorial_remap.html) and can produce some funny, often bizarre imagery, especially when using rainbow coloring. If an input source isn't provided, a [truchet pattern](https://en.wikipedia.org/wiki/Truchet_tiles) will be used.

**UI Elements:** VideoPlaybackSlider, TextCarousel, ImmediateButton, ToggleButton, Slider, StaticMessageBar